{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e259e587-93b2-4af6-afce-a02019f6a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import openai\n",
    "import pprint as pp\n",
    "import prior\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from ai2thor.controller import Controller\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import List, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97640e45-9192-4cff-8573-57b06ff0e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need keys for openai, do so here:\n",
    "with open('openaikey.txt') as f:\n",
    "    api_key = f.read().strip()\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd60696a-e032-42cf-bfa8-7f2c3a754ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI2-THOR WARNING] There has been an update to ProcTHOR-10K that must be used with AI2-THOR version 5.0+. To use the new version of ProcTHOR-10K, please update AI2-THOR to version 5.0+ by running:\n",
      "    pip install --upgrade ai2thor\n",
      "Alternatively, to downgrade to the old version of ProcTHOR-10K, run:\n",
      "   prior.load_dataset(\"procthor-10k\", revision=\"ab3cacd0fc17754d4c080a3fd50b18395fae8647\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:05<00:00, 1912.78it/s]\n",
      "Loading val: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2138.88it/s]\n",
      "Loading test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2090.25it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = prior.load_dataset(\"procthor-10k\")\n",
    "house = dataset[\"train\"][11]\n",
    "controller = Controller(scene=house, visibilityDistance=3, width=750, height=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d05d09e-972f-46a5-a7a4-144f31dd21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = [\"find\", \"describe\", \"move\", \"turn\", \"head\"]\n",
    "\n",
    "class IntegratedAgent:\n",
    "    def __init__(self, controller: object):\n",
    "        # Initialize AI2-THOR controller\n",
    "        self.controller = Controller()\n",
    "        self.controller.step(action=\"Initialize\")\n",
    "        \n",
    "        # Set initial agent position\n",
    "        self.agent_position = self.controller.last_event.metadata[\"agent\"][\"position\"]\n",
    "        \n",
    "        # Initialize room data (from AgentNavigator)\n",
    "        self.room_data = self.initialize_room_data()\n",
    "\n",
    "        # Attributes from Ai2ThorClient\n",
    "        self._answers = []\n",
    "        self._actions = []\n",
    "        self._perceptions = []\n",
    "        self._human_description = \"\"\n",
    "        \n",
    "        # Prompt the human for a description\n",
    "        self.initialize_human_description()\n",
    "\n",
    "    def initialize_room_data(self) -> dict:\n",
    "        return {\n",
    "            'rooms': {\n",
    "                'room_1': {\n",
    "                    'doors': {},\n",
    "                    'visited_doors': set(),\n",
    "                    'visible_objects': {},\n",
    "                    'previous_room': None,\n",
    "                    'visited_positions': {(self.agent_position['x'], self.agent_position['y'], self.agent_position['z'])},\n",
    "                    'visited_objects': set()\n",
    "                }\n",
    "            },\n",
    "            'current_room': 'room_1'\n",
    "        }\n",
    "\n",
    "    def rotate_right(self):\n",
    "        self.controller.step(action='RotateRight', degrees=90)\n",
    "\n",
    "    def rotate_left(self):\n",
    "        self.controller.step(action='RotateLeft', degrees=90)\n",
    "\n",
    "    def get_reachable_positions(self):\n",
    "        event = self.controller.step(action='GetReachablePositions')\n",
    "        return event.metadata['actionReturn']\n",
    "\n",
    "    def calculate_distance(self, position_1, position_2):\n",
    "        pos1 = np.array([position_1['x'], position_1['y'], position_1['z']])\n",
    "        pos2 = np.array([position_2['x'], position_2['y'], position_2['z']])\n",
    "        return np.linalg.norm(pos1 - pos2)\n",
    "\n",
    "    def find_best_position_near_door(self, agent_pos, door_coords):\n",
    "        reachable_positions = self.get_reachable_positions()\n",
    "        reachable_positions.sort(key=lambda pos: self.calculate_distance(pos, door_coords))\n",
    "        closest_four = reachable_positions[:4] if len(reachable_positions) >= 4 else reachable_positions\n",
    "        best_position = max(closest_four, key=lambda pos: self.calculate_distance(pos, agent_pos))\n",
    "        return best_position\n",
    "\n",
    "    def perform_360_view(self):\n",
    "        \"\"\"\n",
    "        Perform a 360° view from the current position and update room data.\n",
    "        Keeping your version of the method, including commented out code.\n",
    "        \"\"\"\n",
    "        current_room_key = self.room_data['current_room']\n",
    "        current_room = self.room_data['rooms'][current_room_key]\n",
    "        images = []\n",
    "\n",
    "        def process_view(event):\n",
    "            images.append(event.frame)\n",
    "            for obj in event.metadata['objects']:\n",
    "                if obj['visible']:\n",
    "                    obj_id = obj['objectId']\n",
    "                    pos = obj['position']\n",
    "                    current_room['visible_objects'][obj_id] = {\n",
    "                        'name': obj['name'],\n",
    "                        'object_type': obj['objectType'],\n",
    "                        'position': pos\n",
    "                    }\n",
    "                    # Store doors\n",
    "                    if obj['objectType'] == 'Doorway' and obj_id not in current_room['doors']:\n",
    "                        current_room['doors'][obj_id] = {\n",
    "                            'coordinates': pos,\n",
    "                            'explored': False\n",
    "                        }\n",
    "\n",
    "        for i in range(4):\n",
    "            event = self.controller.last_event\n",
    "            process_view(event)\n",
    "            if i < 3:\n",
    "                event = self.controller.step(action='RotateRight', degrees=90)\n",
    "\n",
    "        # If you decide to stitch:\n",
    "        panorama = self.stitch_images(images)\n",
    "        panorama_path = \"room_panorama.jpg\"\n",
    "        cv2.imwrite(panorama_path, panorama)\n",
    "        return panorama_path\n",
    "\n",
    "        # Optionally, if you want to keep stitch_images:\n",
    "        def stitch_images(self, images):\n",
    "            cv_images = [cv2.cvtColor(np.array(Image.fromarray(img)), cv2.COLOR_RGB2BGR) for img in images]\n",
    "            stitcher = cv2.Stitcher_create()\n",
    "            status, stitched_image = stitcher.stitch(cv_images)\n",
    "            if status == cv2.Stitcher_OK:\n",
    "                return stitched_image\n",
    "            else:\n",
    "                raise Exception(f\"Image stitching failed with status code {status}\")\n",
    "\n",
    "    def explore_room(self):\n",
    "        current_room_key = self.room_data['current_room']\n",
    "        current_room = self.room_data['rooms'][current_room_key]\n",
    "        agent_pos = self.agent_position\n",
    "        reachable_positions = self.get_reachable_positions()\n",
    "\n",
    "        visited_positions_list = [\n",
    "            {'x': x, 'y': y, 'z': z}\n",
    "            for (x, y, z) in current_room['visited_positions']\n",
    "        ]\n",
    "\n",
    "        positions_within_range = [\n",
    "            pos for pos in reachable_positions\n",
    "            if any(self.calculate_distance(vp, pos) <= 3.0 for vp in visited_positions_list)\n",
    "        ]\n",
    "\n",
    "        unvisited_positions = [\n",
    "            pos for pos in positions_within_range\n",
    "            if (pos['x'], pos['y'], pos['z']) not in current_room['visited_positions']\n",
    "        ]\n",
    "\n",
    "        if not unvisited_positions:\n",
    "            print(\"No new positions to explore within range.\")\n",
    "            return\n",
    "\n",
    "        target_position = max(\n",
    "            unvisited_positions,\n",
    "            key=lambda pos: self.calculate_distance(agent_pos, pos)\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            event = self.controller.step(action='Teleport', position=target_position)\n",
    "            if not event.metadata['lastActionSuccess']:\n",
    "                print(f\"Teleport failed to position: {target_position}\")\n",
    "                return\n",
    "            current_room['visited_positions'].add((target_position['x'], target_position['y'], target_position['z']))\n",
    "            self.agent_position = event.metadata['agent']['position']\n",
    "            print(f\"Agent moved to new position: {target_position}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while moving to new position: {e}\")\n",
    "\n",
    "    def teleport_to_door(self, door_id: str):\n",
    "        current_room_key = self.room_data['current_room']\n",
    "        current_room = self.room_data['rooms'][current_room_key]\n",
    "        agent_pos = self.controller.last_event.metadata['agent']['position']\n",
    "\n",
    "        door_info = current_room['doors'][door_id]\n",
    "        door_coords = door_info['coordinates']\n",
    "\n",
    "        target_position = self.find_best_position_near_door(agent_pos, door_coords)\n",
    "        if not target_position:\n",
    "            print(\"No valid position found near the door.\")\n",
    "            return False\n",
    "        try:\n",
    "            event = self.controller.step(action='Teleport', position=target_position)\n",
    "            if not event.metadata['lastActionSuccess']:\n",
    "                print(f\"Failed to teleport to position {target_position}.\")\n",
    "                return False\n",
    "            self.agent_position = event.metadata['agent']['position']\n",
    "        except Exception as e:\n",
    "            print(f\"Exception occurred during teleport: {e}\")\n",
    "            return False\n",
    "\n",
    "        current_room['doors'][door_id]['explored'] = True\n",
    "\n",
    "        room_number = len(self.room_data['rooms']) + 1\n",
    "        new_room_key = f\"room_{room_number}\"\n",
    "        if new_room_key not in self.room_data['rooms']:\n",
    "            self.room_data['rooms'][new_room_key] = {\n",
    "                'doors': {},\n",
    "                'visited_doors': set(),\n",
    "                'visible_objects': {},\n",
    "                'previous_room': current_room_key,\n",
    "                'visited_positions': {(self.agent_position['x'], self.agent_position['y'], self.agent_position['z'])},\n",
    "                'visited_objects': set()\n",
    "            }\n",
    "\n",
    "            self.room_data['rooms'][new_room_key]['doors'][door_id] = {\n",
    "                'coordinates': door_coords,\n",
    "                'explored': True\n",
    "            }\n",
    "            self.room_data['current_room'] = new_room_key\n",
    "        print(f\"Entered new room: {new_room_key}\")\n",
    "        self.close_door()\n",
    "        print(\"Closed the door.\")\n",
    "\n",
    "    def close_door(self):\n",
    "        event = self.controller.last_event\n",
    "        objects = event.metadata['objects']\n",
    "\n",
    "        open_doors = [\n",
    "            obj for obj in objects\n",
    "            if obj['objectType'] == 'Doorway' and obj.get('openable', False) and obj.get('isOpen', False)\n",
    "        ]\n",
    "\n",
    "        if not open_doors:\n",
    "            print(\"No open doors found.\")\n",
    "            return\n",
    "\n",
    "        closest_door = min(\n",
    "            open_doors,\n",
    "            key=lambda d: self.calculate_distance(self.agent_position, d['position'])\n",
    "        )\n",
    "\n",
    "        door_id = closest_door['objectId']\n",
    "        close_event = self.controller.step(action='CloseObject', objectId=door_id)\n",
    "        if not close_event.metadata['lastActionSuccess']:\n",
    "            print(\"Failed to close the door.\")\n",
    "\n",
    "    def switch_new_room(self):\n",
    "        current_room_key = self.room_data['current_room']\n",
    "        current_room = self.room_data['rooms'][current_room_key]\n",
    "\n",
    "        unexplored_doors = [\n",
    "            (door_id, door_info) for door_id, door_info in current_room['doors'].items()\n",
    "            if not door_info['explored']\n",
    "        ]\n",
    "        if not unexplored_doors:\n",
    "            print(\"No unexplored doors available in the current room.\")\n",
    "            return False\n",
    "\n",
    "        door_id, _ = unexplored_doors[0]\n",
    "        return self.teleport_to_door(door_id)\n",
    "\n",
    "    def return_previous_room(self):\n",
    "        current_room_key = self.room_data['current_room']\n",
    "        current_room = self.room_data['rooms'][current_room_key]\n",
    "        prev_room_key = current_room.get('previous_room', None)\n",
    "\n",
    "        if not prev_room_key:\n",
    "            print(\"No previous room recorded. Cannot return.\")\n",
    "            return False\n",
    "\n",
    "        previous_room = self.room_data['rooms'][prev_room_key]\n",
    "        visited_positions = previous_room.get('visited_positions', None)\n",
    "\n",
    "        if not visited_positions:\n",
    "            print(f\"No visited positions recorded for previous room: {prev_room_key}\")\n",
    "            return False\n",
    "\n",
    "        visited_positions_list = list(visited_positions)\n",
    "        chosen_pos_tuple = random.choice(visited_positions_list)\n",
    "        chosen_pos = {'x': chosen_pos_tuple[0], 'y': chosen_pos_tuple[1], 'z': chosen_pos_tuple[2]}\n",
    "\n",
    "        event = self.controller.step(action='Teleport', position=chosen_pos)\n",
    "        if event.metadata['lastActionSuccess']:\n",
    "            self.agent_position = event.metadata['agent']['position']\n",
    "            self.room_data['current_room'] = prev_room_key\n",
    "            print(f\"Returned to previous room: {prev_room_key} at {chosen_pos}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to teleport to position {chosen_pos} in previous room {prev_room_key}.\")\n",
    "            return False\n",
    "\n",
    "    # Methods from Ai2ThorClient (adjusted to use self.controller):\n",
    "    def initialize_human_description(self):\n",
    "        print(\"Robot> Please describe in one sentence what you see in the image shown.\")\n",
    "        human_input = input(\"Evaluator> \")\n",
    "        self._human_description = human_input.strip()\n",
    "        print(f\"Robot> Thank you! I have stored your description: \\\"{self._human_description}\\\"\")\n",
    "\n",
    "    def search_for_object_in_view(self, objectType):\n",
    "        event = self.controller.last_event\n",
    "        found = []\n",
    "        for obj in event.metadata['objects']:\n",
    "            if obj['objectType'].lower() == objectType.lower():\n",
    "                coord = obj['position']\n",
    "                found.append((obj, objectType, coord, Image.fromarray(event.frame)))\n",
    "        return found\n",
    "\n",
    "    def search_for_object(self, objectType):\n",
    "        answer = \"\"\n",
    "        found = self.search_for_object_in_view(objectType)\n",
    "        rotate = 0\n",
    "        while not found and rotate < 4:\n",
    "            self.controller.step(action=\"RotateRight\", degrees=90)\n",
    "            found = self.search_for_object_in_view(objectType)\n",
    "            rotate += 1\n",
    "        if not found:\n",
    "            answer = \"I could not find it. Tell me to move?\"\n",
    "        else:\n",
    "            answer = f\"I found {len(found)} instances of type {objectType} in my view.\"\n",
    "            for f, objectType, coord, _ in found:\n",
    "                answer += f\"\\n{f['name']} at {coord}\"\n",
    "        return answer, found\n",
    "\n",
    "    def what_do_you_see(self):\n",
    "        event = self.controller.last_event\n",
    "        answer = f\"I see {len(event.metadata['objects'])} things there.\\n\"\n",
    "        for obj in event.metadata['objects']:\n",
    "            answer += obj['objectType'] + \"\\n\"\n",
    "        return answer\n",
    "\n",
    "    def do_action(self, action, target):\n",
    "        # This will depend on whether you have Action enums or not.\n",
    "        # For simplicity, let's handle moves as strings:\n",
    "        answer = \"\"\n",
    "        found_objects = []\n",
    "        if action == \"find\":\n",
    "            answer, found_objects = self.search_for_object(target)\n",
    "        elif action == \"head\":\n",
    "            if target == \"up\":\n",
    "                self.controller.step(action=\"LookUp\")\n",
    "            elif target == \"down\":\n",
    "                self.controller.step(action=\"LookDown\")\n",
    "        elif action in [\"move\", \"turn\"]:\n",
    "            if target == \"forward\":\n",
    "                self.controller.step(action=\"MoveAhead\")\n",
    "            elif target == \"back\":\n",
    "                self.controller.step(action=\"MoveBack\")\n",
    "            elif target == \"left\":\n",
    "                self.controller.step(action=\"RotateLeft\", degrees=90)\n",
    "            elif target == \"right\":\n",
    "                self.controller.step(action=\"RotateRight\", degrees=90)\n",
    "        return answer, found_objects\n",
    "\n",
    "    def capture_scene_frame(self):\n",
    "        image = Image.fromarray(self.controller.last_event.frame)\n",
    "        image_path = \"captured_image.jpg\"\n",
    "        image.save(image_path)\n",
    "        return image_path\n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    def describe_image_with_gpt(self, image_path):\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a visual assistant. Describe the contents of images provided. Remember to also mention the number of each type of objects there.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                          \"type\": \"text\",\n",
    "                          \"text\": \"What’s in this image?\"\n",
    "                        },\n",
    "                        {\n",
    "                          \"type\": \"image_url\",\n",
    "                          \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                          }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 200\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers={\"Authorization\": f\"Bearer {openai.api_key}\", \"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            raise Exception(f\"Failed to get GPT response. Status: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "    def describe_image_object_with_gpt(self, target, image_path):\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a visual assistant. Describe the contents of images provided.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                    {\n",
    "                      \"type\": \"text\",\n",
    "                      \"text\": f\"Describe the '{target}' in the image.\"\n",
    "                    },\n",
    "                    {\n",
    "                      \"type\": \"image_url\",\n",
    "                      \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                      }\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 100\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers={\"Authorization\": f\"Bearer {openai.api_key}\", \"Content-Type\": \"application/json\"},\n",
    "            json=payload\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        else:\n",
    "            raise Exception(f\"Failed to get GPT response. Status: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "    def nlu_parse(self, prompt):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"You are a virtual assistant for controlling a robot. Convert the user's natural language instructions into a JSON object with the format: {\"action\": \"<action>\", \"target\": \"<target>\"}. If the user asks a general question or does not provide a target, return {\"action\": \"<action>\", \"target\": \"\"}.\"The robot can perform actions in {ACTIONS} like \"find\", \"describe\", \"move\", \"turn\", \"head\". Action \"move\" and \"turn\" should be linked with target \"forward\", \"back\", \"left\" or \"right\". Action 'head' should be connected with target 'up' or 'down'.\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            structured_command = response['choices'][0]['message']['content']\n",
    "            return json.loads(structured_command)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse GPT response into a dictionary: {e}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Unexpected error while parsing instruction: {e}\")\n",
    "\n",
    "    def compare_descriptions(self, ai_description, human_description):\n",
    "        # Using GPT to compare (as in original Ai2ThorClient)\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": (\n",
    "                            \"An agent and a human will separately give you a description of what they see. Provide a confidence level (0-100%) that the two scenes overlap.\"\n",
    "                        ),\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": f\"Human description: {human_description}\\nRobot description: {ai_description}\"},\n",
    "                ],\n",
    "                max_tokens=10,\n",
    "                temperature=0,\n",
    "            )\n",
    "            confidence = response['choices'][0]['message']['content'].strip()\n",
    "            return int(confidence)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during confidence assessment: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def process_instruction(self, prompt):\n",
    "        self._answers = []\n",
    "        self._actions = []\n",
    "        self._perceptions = []\n",
    "        answer = \"\"\n",
    "\n",
    "        try:\n",
    "            parsed_command = self.nlu_parse(prompt)\n",
    "            action = parsed_command.get(\"action\", \"\").lower()\n",
    "            target = parsed_command.get(\"target\", \"\").lower()\n",
    "\n",
    "            if action in ACTIONS:\n",
    "                if action == \"describe\" and target == '':\n",
    "                    # Describe current scene\n",
    "                    confirmation_message = \"I understand. You want me to describe what I see.\"\n",
    "                    self._answers.append(confirmation_message)\n",
    "                    image_path = self.capture_scene_frame()\n",
    "                    description = self.describe_image_with_gpt(image_path)\n",
    "                    human_desc = self._human_description\n",
    "                    confidence_level = self.compare_descriptions(human_desc, description)\n",
    "                    self._answers.append(description + f\" I think there is a possibility of '{confidence_level}'% overlap.\")\n",
    "                elif action == \"describe\" and target != '':\n",
    "                    # Describe a specific object\n",
    "                    confirmation_message = f\"I understand. You want me to describe that object '{target}'.\"\n",
    "                    self._answers.append(confirmation_message)\n",
    "                    image_path = self.capture_scene_frame()\n",
    "                    description = self.describe_image_object_with_gpt(target, image_path)\n",
    "                    self._answers.append(description)\n",
    "                else:\n",
    "                    confirmation_message = f\"I understand. I will now '{action}' with the target '{target}'...\"\n",
    "                    self._answers.append(confirmation_message)\n",
    "\n",
    "                answer, found_objects = self.do_action(action, target)\n",
    "                if answer:\n",
    "                    self._answers.append(answer)\n",
    "                if found_objects:\n",
    "                    self._perceptions.extend(found_objects)\n",
    "            else:\n",
    "                error_message = f\"Sorry, I do not understand the action '{action}'.\"\n",
    "                self._answers.append(error_message)\n",
    "                print(error_message)\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error processing the instruction: {str(e)}\"\n",
    "            self._answers.append(error_message)\n",
    "            print(error_message)\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d52392b-92f9-47e6-a5b6-11eac6c25155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot> Please describe in one sentence what you see in the image shown.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Evaluator>  I see a table, three chairs, a kitchen, a couch, a rug, and a painting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot> Thank you! I have stored your description: \"I see a table, three chairs, a kitchen, a couch, a rug, and a painting.\"\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "navigator = IntegratedAgent(controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af209ee-b5ec-4dd4-8beb-fc28bd881da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
