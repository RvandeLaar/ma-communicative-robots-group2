{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c045b6f-2966-40da-bbf0-2cca52370a3b",
   "metadata": {},
   "source": [
    "## Llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b8c17-89bd-41d3-82fb-5999f9c08d83",
   "metadata": {},
   "source": [
    "This notebook shows how you can chat with Llama through an EMISSOR client. The EMISSOR layer will capture the interaction as a scenario for further analysis.\n",
    "For chatting with a LLama model, we use the [LangChain layer on top of Ollama](https://api.python.langchain.com/en/latest/chat_models/langchain_ollama.chat_models.ChatOllama.html). \n",
    "\n",
    "Ollama allows you to pull a model from the web to your local machine and use a ```chat``` function to send instructions to local model to get a response. \n",
    "\n",
    "```\n",
    "https://github.com/ollama/ollama\n",
    "```\n",
    "\n",
    "Instead of the Ollama ```chat``` function, we will create a client through ChatOllama so that we can set parameters for the behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b76e5-6d8a-4091-b529-802049c5e39b",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26547e64-b644-44da-9685-592e73d528fb",
   "metadata": {},
   "source": [
    "The following dependencies need to be installed for this notebook. The dependencies are in the requirements.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66457f-d098-46b4-aca3-876400dcc702",
   "metadata": {},
   "source": [
    "* pip install emissor\n",
    "* pip install cltl.combots\n",
    "* pip install ollama\n",
    "* pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e213902-fd4d-4d5a-9d17-8c558af190db",
   "metadata": {},
   "source": [
    "There are various versions of models. We are going to pull the smallest Llama3.2 model that already gives reasonable performance but only works for text input.\n",
    "To be able to access the model through Ollama, we need to pull it from the terminal in the same virtual environment:\n",
    "\n",
    "```\n",
    "ollama pull llama3.2:1b\n",
    "```\n",
    "\n",
    "You only need to do this once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63864de-b1c2-4051-9a2f-23bc2dbb84ee",
   "metadata": {},
   "source": [
    "### Loading Llama in ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54334a9-b0bc-440d-868d-924a772b9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llama_model = \"llama3.2:1b\" ### 1B\n",
    "#llama_model = \"llama3.2\" ### 3B\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = llama_model,\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e96a772-4705-4291-941e-909658eae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct = { 'role': 'system', 'content': \"You are a docter and you will receive questions from patients. Be brief and no more than two sentences.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387c124-7772-4511-9afb-cb83449ca47a",
   "metadata": {},
   "source": [
    "### Creating an EMISSOR client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a29313-9cd6-4321-9f0d-fd2746ae2ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from leolani_client import LeolaniChatClient\n",
    "emissor_path = \"./emissor\"\n",
    "HUMAN=\"Piek\"\n",
    "AGENT=\"Llama\"\n",
    "leolaniClient = LeolaniChatClient(emissor_path=emissor_path, agent=AGENT, human=HUMAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f437945-4b5c-418a-b9a1-55b7435d5da6",
   "metadata": {},
   "source": [
    "### Interaction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c20767-aca6-4a26-b423-2ab3ba5f6b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066b4f9-52e6-49fe-85b6-d733f1573e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa6d0c3-a5fa-4a5a-b2f9-093ee36aba51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a docter and you will receive questions from patients. Be brief and no more than two sentences.'}]\n",
      "Llama: <|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm ready to answer your questions as a doctor. What's on your mind?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Hi Doctor, I am not feeling well. Can you help me?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: Hi Doctor, I am not feeling well. Can you help me?\n",
      "Llama: I'm so sorry to hear that you're not feeling well. Can you tell me more about what's been going on - have you experienced any persistent symptoms like fever, vomiting, or diarrhea, or has it started suddenly and unexpectedly?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I have fever and vomitting and red spots on my back.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I have fever and vomitting and red spots on my back.\n",
      "Llama: Fever and vomiting can be concerning symptoms that require attention. The presence of red spots on your back could be a sign of a skin infection or abscess, but it's essential to rule out other potential causes as well.\n",
      "\n",
      "Can you tell me more about the fever - how long have you had it, and is it accompanied by any other symptoms like headache, fatigue, or nausea?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Three days\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: Three days\n",
      "Llama: It sounds like you've been experiencing a bit of a worsening of your symptoms over the past three days. The presence of fever, vomiting, and red spots on your back suggests that there may be an infection or an abscess forming somewhere in your body.\n",
      "\n",
      "Can you tell me more about when these symptoms started? Did they suddenly begin, or did they develop gradually over a few hours or days? Have you noticed any other symptoms like pain, swelling, or pus discharge from the affected area?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Yes suddenly three days ago\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: Yes suddenly three days ago\n",
      "Llama: The sudden onset of your symptoms, particularly the fever and vomiting, along with the skin lesion on your back, suggests a possible skin infection or abscess. Can you tell me more about this lesion? Is it painful, tender to the touch, or has it changed in size or shape over time?\n",
      "\n",
      "Is the lesion tender when you press on it, or does it feel like it's hard and firm to the touch? Has it been increasing in size over the past few days, or is it relatively stationary?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " hard and firm to touch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: hard and firm to touch\n",
      "Llama: Those symptoms sound concerning, with the sudden onset of high fever, vomiting, and skin lesions on your back, which have become hard and firm to the touch.\n",
      "\n",
      "Can you tell me more about these lesions? Are they painless or does it hurt when you press on them?\n",
      "\n",
      "And what are the red spots exactly like - are they raised, flat, or do they have any distinct edges?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " raised with distinct edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: raised with distinct edges\n",
      "Llama: Those symptoms are concerning, especially the sudden onset of high fever, vomiting, skin lesions (red spots on your back), and a hard, firm lesion that's raised with distinct edges. I'm going to need some more information from you.\n",
      "\n",
      "Can you please tell me when exactly did these symptoms start for you? And have you noticed any other symptoms like headache, fatigue, or nausea before they began?\n",
      "\n",
      "Also, how long have you been experiencing the skin lesions on your back? Have they been changing in size or shape over time?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " No they were there after the first day\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: No they were there after the first day\n",
      "Llama: It sounds like you're experiencing a concerning combination of symptoms. I want to make sure I understand everything accurately before I provide any guidance.\n",
      "\n",
      "To summarize:\n",
      "\n",
      "* You have a high fever that has been increasing over the past three days.\n",
      "* You've also experienced vomiting, which could be related to your overall condition or potentially a gastrointestinal issue.\n",
      "* Recently, you developed red spots on your back that are hard and firm to the touch. These lesions appeared suddenly about three days ago.\n",
      "\n",
      "Given this information, I'm going to take some additional questions from you to better understand what might be happening. Can you tell me:\n",
      "\n",
      "* Are there any other symptoms besides the fever, vomiting, and skin lesions on your back? For example, are you experiencing headaches, fatigue, or difficulty breathing?\n",
      "* Have you noticed any changes in your appetite or water intake recently?\n",
      "* Do you have a weakened immune system or take any medications that might be affecting your health?\n",
      "\n",
      "Please let me know as much information as possible so I can provide the best guidance and support.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Thanks, bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: Thanks, bye\n",
      "Llama: I'm so sorry to hear that you're not feeling well. I've noted your symptoms in our medical history, including:\n",
      "\n",
      "* Fever for 3 days\n",
      "* Vomiting\n",
      "* Red spots on your back (which appeared suddenly about 3 days ago)\n",
      "* Lesions are hard and firm to the touch with distinct edges\n",
      "\n",
      "I'll schedule an appointment for you to see me as soon as possible. In the meantime, can you tell me a bit more about what's been going on - have you noticed any other symptoms like headache, fatigue, or nausea?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: bye\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "history.append(instruct)\n",
    "print(history)\n",
    "### First prompt\n",
    "response = llm.invoke(history)\n",
    "utterance = response.content\n",
    "print(AGENT + \": \" + utterance)\n",
    "leolaniClient._add_utterance(AGENT, utterance) \n",
    "prompt = { 'role': 'system', 'content': utterance}\n",
    "history.append(prompt)\n",
    "\n",
    "utterance = input(\"\\n\")\n",
    "print(HUMAN + \": \" + utterance)\n",
    "leolaniClient._add_utterance(HUMAN, utterance)\n",
    "prompt = { 'role': 'user', 'content': utterance}\n",
    "history.append(prompt)\n",
    "\n",
    "while not (utterance.lower() == \"stop\" or utterance.lower() == \"bye\"):\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    response = llm.invoke(history)\n",
    "    utterance = response.content\n",
    "    print(AGENT + \": \" + utterance)\n",
    "    leolaniClient._add_utterance(AGENT, utterance) \n",
    "    prompt = { 'role': 'system', 'content': utterance}\n",
    "    history.append(prompt)\n",
    "\n",
    "    utterance = input(\"\\n\")\n",
    "    print(HUMAN + \": \" + utterance)\n",
    "    leolaniClient._add_utterance(HUMAN, utterance)\n",
    "    prompt = { 'role': 'user', 'content': utterance}\n",
    "    history.append(prompt)\n",
    "\n",
    "##### After completion, we save the scenario in the defined emissor folder.\n",
    "leolaniClient._save_scenario() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1136a7a-2284-46ff-80b3-00247195e022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
