{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c738eb7-7a57-4f2f-b009-6f7269b20b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install openai==0.28.0\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e259e587-93b2-4af6-afce-a02019f6a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prior\n",
    "import openai\n",
    "\n",
    "from integrated_agent import Agent, ACTIONS\n",
    "from leolani_client import LeolaniChatClient, Action\n",
    "from ai2thor.controller import Controller\n",
    "from ipywidgets import Text, Button, Output, VBox, HBox\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf3e5e82-25dd-46f4-9444-71bc7c192e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scene\n",
    "#dataset = prior.load_dataset(\"procthor-10k\")\n",
    "#house = dataset[\"train\"][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e1b1862-5105-42b5-80df-43f081f671fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI2-THOR WARNING] There has been an update to ProcTHOR-10K that must be used with AI2-THOR version 5.0+. To use the new version of ProcTHOR-10K, please update AI2-THOR to version 5.0+ by running:\n",
      "    pip install --upgrade ai2thor\n",
      "Alternatively, to downgrade to the old version of ProcTHOR-10K, run:\n",
      "   prior.load_dataset(\"procthor-10k\", revision=\"ab3cacd0fc17754d4c080a3fd50b18395fae8647\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4874.99it/s]\n",
      "Loading val: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 5163.10it/s]\n",
      "Loading test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 4644.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = prior.load_dataset(\"procthor-10k\")\n",
    "dataset[\"train\"][5808][\"objects\"][9][\"children\"][2] = {\n",
    "  'assetId': 'Laptop_13',\n",
    "  'id': \"Laptop|surface|10|71\",\n",
    "  'kinematic': False,\n",
    "  'openness': 0,\n",
    "  'position': {'x': 5.308516502380371,\n",
    "  'y': 0.960530161857605,\n",
    "  'z': 3.317396640777588},\n",
    "  'rotation': {'x': -0.0, 'y': 0.0, 'z': 0.0},\n",
    "  'layer': 'Procedural1'}\n",
    "\n",
    "house = dataset[\"train\"][5808]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97640e45-9192-4cff-8573-57b06ff0e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI key\n",
    "with open('openaikey.txt') as f:\n",
    "    api_key = f.read().strip()\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd60696a-e032-42cf-bfa8-7f2c3a754ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single controller instance\n",
    "controller = Controller(\n",
    "    scene=house,\n",
    "    visibilityDistance=10,\n",
    "    width=750,\n",
    "    height=750\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "060ee252-6a7c-4fea-8758-ac1513f68534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730dc9ab2bf842ac81cea96e0a02e819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='User:', layout=Layout(width='50%'), placeholder='Type your message …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emissor_path = \"./emissor\"\n",
    "HUMAN = \"User\"\n",
    "AGENT = \"AI2Thor\"\n",
    "\n",
    "leolaniClient = LeolaniChatClient(emissor_path=emissor_path, agent=AGENT, human=HUMAN)\n",
    "agent = Agent(controller=controller)\n",
    "\n",
    "actions_available = \", \".join(ACTIONS)\n",
    "initial_utterance = f\"Hi, I am your navigational agent. I can describe what I see, describe an exact object, move backfoward, turn left or right. I can teleport to another room if you tell me to teleport or change room to explore. If you thought you found some interesting object from my description, please ask me to find the object in my view, and I'll return you the object id. These are the actions I can perform for you: {actions_available}.\"\n",
    "\n",
    "human_turn_count = 0\n",
    "agent_turn_count = 0\n",
    "\n",
    "output_area = Output()\n",
    "user_input = Text(\n",
    "    value='',\n",
    "    placeholder='Type your message here...',\n",
    "    description='User:',\n",
    "    disabled=False,\n",
    "    layout={'width': '50%'}\n",
    ")\n",
    "send_button = Button(description=\"Send\", button_style='success')\n",
    "\n",
    "# Print initial message\n",
    "with output_area:\n",
    "    print(AGENT + \">\" + initial_utterance)\n",
    "leolaniClient._add_utterance(AGENT, initial_utterance)\n",
    "agent_turn_count += 1  # Agent turn\n",
    "\n",
    "# Ask the human for initial description\n",
    "with output_area:\n",
    "    print(\"Robot> Please describe in as much detail the room you see in the image shown. Also, describe the object you hope to find.\")\n",
    "agent_turn_count += 1  # Agent turn\n",
    "\n",
    "conversation_active = True\n",
    "human_description_stored = False\n",
    "\n",
    "def on_send_clicked(b):\n",
    "    global conversation_active, human_description_stored, turn_count\n",
    "\n",
    "    utterance = user_input.value.strip()\n",
    "    user_input.value = \"\"\n",
    "    if not utterance:\n",
    "        return\n",
    "\n",
    "    # Human utterance\n",
    "    with output_area:\n",
    "        print(HUMAN + \">\" + utterance)\n",
    "    leolaniClient._add_utterance(HUMAN, utterance)\n",
    "    human_turn_count += 1  # Human turn\n",
    "\n",
    "    if utterance.lower() in [\"stop\", \"bye\", \"exit\"]:\n",
    "        conversation_active = False\n",
    "        agent.controller.stop()\n",
    "        leolaniClient._save_scenario()\n",
    "        with output_area:\n",
    "            print(\"Scenario saved and interaction ended.\")\n",
    "        send_button.disabled = True\n",
    "        user_input.disabled = True\n",
    "        return\n",
    "\n",
    "    if not human_description_stored:\n",
    "        # The first user response is the human description\n",
    "        agent._human_description = utterance\n",
    "        human_description_stored = True\n",
    "        with output_area:\n",
    "            print(AGENT + \"> Thank you! I have stored your description. Maybe you want me to start navigation?\")\n",
    "        leolaniClient._add_utterance(AGENT, \"Thank you! I have stored your description. Maybe you want me to start navigation?\")\n",
    "        agent_turn_count += 1  # Agent turn\n",
    "\n",
    "        # Now perform a 360 view, describe, and show confidence\n",
    "        panorama_path = agent.perform_360_view()  # increments actions inside\n",
    "        description = agent.describe_image_with_gpt(panorama_path)\n",
    "        confidence_level = agent.compare_descriptions(description, agent._human_description)\n",
    "        reply = f\"In the room I started, I see the following: {description}.\\nI think there is a possibility of '{confidence_level}'% that the object shows in my current view.\\nWhat would you like to do next?\"\n",
    "        with output_area:\n",
    "            print(AGENT + \">\" + reply)\n",
    "        leolaniClient._add_utterance(AGENT, reply)\n",
    "        agent_turn_count += 1  # Agent turn\n",
    "\n",
    "        return\n",
    "\n",
    "    # For subsequent utterances, process normally\n",
    "    agent.process_instruction(utterance)\n",
    "\n",
    "    for ans in agent._answers:\n",
    "        with output_area:\n",
    "            print(AGENT + \">\" + ans)\n",
    "        leolaniClient._add_utterance(AGENT, ans)\n",
    "        agent_turn_count += 1  # Agent turn for each response\n",
    "\n",
    "    for obj, objectType, coord, image in agent._perceptions:\n",
    "        leolaniClient._add_image(obj['name'], objectType, coord, image)\n",
    "\n",
    "    for action in agent._actions:\n",
    "        leolaniClient._add_action(action)\n",
    "\n",
    "    # Clear for next round\n",
    "    agent._answers.clear()\n",
    "    agent._perceptions.clear()\n",
    "    agent._actions.clear()\n",
    "\n",
    "send_button.on_click(on_send_clicked)\n",
    "display(VBox([user_input, send_button, output_area]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af209ee-b5ec-4dd4-8beb-fc28bd881da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of dialogue turns used by human: {human_turn_count}.\")\n",
    "print(f\"Number of dialogue turns used by agent: {agent_turn_count}.\")\n",
    "print(f\"Total number of dialogue turns used: {human_turn_count + agent_turn_count}.\")\n",
    "print(f\"Number of actions undertaken by the agent to search for the object {agent.actions}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9323223-f62f-4333-be85-d33b3531cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c90b1-bb27-46d5-886d-fe32412c8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict['test_1'] = {\n",
    "    'human_turn_count': human_turn_count,\n",
    "    'agent_turn_count': agent_turn_count,\n",
    "    'total_turn_count': human_turn_count + agent_turn_count,\n",
    "    'action_count': agent.actions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7152fbd0-b35d-41b9-9f1b-8848a9f3b5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
